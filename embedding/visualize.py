"""
visualize.py
------------
Visual embedding utilities for dataset exploration and bias diagnosis.

Integrates with outputs from indexer.py:
    - embeddings_resnet18.npy
    - faiss.index
    - image_ids.txt
    - labels.npy
    - knn_graph.npy

Provides:
- load_embedding_data(): unified loader for FAISS + NumPy outputs.
- reduce_embeddings(): dimensionality reduction (UMAP, PCA, t-SNE)
- plot_embedding_scatter(): interactive 2D/3D visualization
- plot_similarity_heatmap(): cosine or kNN-based similarity overview
- visualize_knn_graph(): visualize clusters based on saved kNN graph
- visualize_outliers(): highlight anomalous embeddings
"""
import plotly.io as pio
pio.renderers.default = "browser"
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap
import plotly.express as px
import plotly.graph_objects as go
from sklearn.metrics.pairwise import cosine_similarity
import os


# Load and Prepare Data Utilities
def load_embedding_data(base_dir="."):
    """
    Load embeddings, labels, and kNN graph generated by indexer.py.
    Args:
        base_dir (str): path containing generated files.
    Returns:
        dict: containing embeddings, labels, ids, knn graph
    """
    paths = {
        "embeddings": os.path.join(base_dir, "embeddings_resnet18.npy"),
        "labels": os.path.join(base_dir, "labels.npy"),
        "ids": os.path.join(base_dir, "image_ids.txt"),
        "knn_graph": os.path.join(base_dir, "knn_graph.npy"),
    }

    data = {}
    if os.path.exists(paths["embeddings"]):
        data["embeddings"] = np.load(paths["embeddings"])
        print(f"[Loaded] embeddings_resnet18.npy → {data['embeddings'].shape}")
    else:
        raise FileNotFoundError("Missing embeddings_resnet18.npy")

    if os.path.exists(paths["labels"]):
        data["labels"] = np.load(paths["labels"], allow_pickle=True)
        print(f"[Loaded] labels.npy → {len(data['labels'])} labels")
    else:
        data["labels"] = None

    if os.path.exists(paths["ids"]):
        with open(paths["ids"], "r") as f:
            data["ids"] = [line.strip() for line in f.readlines()]
        print(f"[Loaded] image_ids.txt → {len(data['ids'])} IDs")
    else:
        data["ids"] = None

    if os.path.exists(paths["knn_graph"]):
        graph = np.load(paths["knn_graph"], allow_pickle=True).item()
        data["knn_distances"], data["knn_indices"] = graph["similarities"], graph["indices"]
        print(f"[Loaded] knn_graph.npy → {data['knn_indices'].shape}")
    else:
        data["knn_distances"], data["knn_indices"] = None, None

    return data


# Dimensionality Reduction
def reduce_embeddings(embeddings, method="umap", n_components=2, random_state=42):
    """
    Reduce high-dimensional embeddings for visualization.
    """
    print(f"[Reducing] Method={method}, Components={n_components}")
    if method == "pca":
        reducer = PCA(n_components=n_components, random_state=random_state)
    elif method == "tsne":
        reducer = TSNE(n_components=n_components, random_state=random_state, perplexity=30)
    else:
        reducer = umap.UMAP(n_components=n_components, random_state=random_state, min_dist=0.1)
    return reducer.fit_transform(embeddings)


#  Interactive Embedding Scatter
def plot_embedding_scatter(
    reduced_emb,
    labels=None,
    ids=None,
    color_by=None,
    title="Embedding Projection",
    size=None,
    hover_extra=None,
    color_scale="Viridis",
):
    """
    Interactive 2D or 3D scatter plot for embeddings.
    """
    df = pd.DataFrame(reduced_emb, columns=[f"dim{i+1}" for i in range(reduced_emb.shape[1])])
    if labels is not None:
        df["label"] = labels
    if ids is not None:
        df["id"] = ids
    if color_by is not None:
        df["color"] = color_by
    if size is not None:
        df["size"] = size
    if hover_extra is not None:
        for k, v in hover_extra.items():
            df[k] = v

    hover_fields = ["id", "label"] if "id" in df and "label" in df else df.columns
    color_field = "color" if color_by is not None else "label"

    if reduced_emb.shape[1] == 3:
        fig = px.scatter_3d(
            df, x="dim1", y="dim2", z="dim3",
            color=color_field, hover_data=hover_fields,
            size="size" if size is not None else None,
            color_continuous_scale=color_scale, title=title,
        )
    else:
        fig = px.scatter(
            df, x="dim1", y="dim2",
            color=color_field, hover_data=hover_fields,
            size="size" if size is not None else None,
            color_continuous_scale=color_scale, title=title,
        )

    fig.update_traces(marker=dict(opacity=0.8, line=dict(width=0)))
    fig.update_layout(template="plotly_white")
    return fig


# Similarity Heatmap
def plot_similarity_heatmap(embeddings, labels=None, sample_size=100):
    """
    Plot cosine similarity matrix for a random subset.
    """
    idx = np.random.choice(len(embeddings), min(sample_size, len(embeddings)), replace=False)
    sub_emb = embeddings[idx]
    sim = cosine_similarity(sub_emb)

    label_names = labels[idx] if labels is not None else [str(i) for i in idx]
    fig = go.Figure(data=go.Heatmap(z=sim, x=label_names, y=label_names, colorscale="Viridis"))
    fig.update_layout(
        title=f"Cosine Similarity Heatmap (n={len(idx)})",
        xaxis_title="Samples",
        yaxis_title="Samples",
    )
    return fig

#  kNN Graph Visualization
def visualize_knn_graph(reduced_emb, knn_indices, labels=None):
    """
    Visualize embedding clusters with connecting edges based on kNN graph.
    """
    if knn_indices is None:
        raise ValueError("kNN graph not found. Run indexer.py first.")

    fig = go.Figure()

    # Draw edges
    for i, neighbors in enumerate(knn_indices):
        for j in neighbors:
            fig.add_trace(
                go.Scatter(
                    x=[reduced_emb[i, 0], reduced_emb[j, 0]],
                    y=[reduced_emb[i, 1], reduced_emb[j, 1]],
                    mode="lines",
                    line=dict(width=0.5, color="lightgray"),
                    hoverinfo="none",
                    showlegend=False,
                )
            )

    # Draw nodes
    node_trace = go.Scatter(
        x=reduced_emb[:, 0],
        y=reduced_emb[:, 1],
        mode="markers",
        marker=dict(
            color=labels if labels is not None else "blue",
            size=6,
            opacity=0.8,
            colorscale="Viridis",
            showscale=True if labels is not None else False,
        ),
        text=labels if labels is not None else None,
        hoverinfo="text",
    )
    fig.add_trace(node_trace)
    fig.update_layout(title="kNN Graph Projection", showlegend=False, template="plotly_white")
    return fig


#  Outlier / Influence Visualization

def visualize_outliers(reduced_emb, outlier_scores, threshold=0.95):
    """
    Visualize high-outlier-score points distinctly.
    Args:
        reduced_emb (np.ndarray): 2D embeddings
        outlier_scores (np.ndarray): float scores [0, 1]
        threshold (float): quantile cutoff for highlighting outliers
    Returns:
        plotly Figure
    """
    is_outlier = outlier_scores >= np.quantile(outlier_scores, threshold)
    
    # Make labels more readable
    labels = np.where(is_outlier, "Outlier", "Normal")
    
    fig = px.scatter(
        x=reduced_emb[:, 0],
        y=reduced_emb[:, 1],
        color=labels,
        color_discrete_map={"Outlier": "red", "Normal": "lightgray"},
        title=f"Outlier Visualization (Top {int((1-threshold)*100)}% Outliers)",
        labels={"x": "dim1", "y": "dim2"},
    )
    fig.update_traces(marker=dict(size=6, opacity=0.7))
    return fig


def plot_embedding_variance(embeddings):
    """Bar chart of variance explained by top PCA components."""
    pca = PCA(n_components=min(30, embeddings.shape[1]))
    pca.fit(embeddings)
    var_ratio = pca.explained_variance_ratio_
    fig = go.Figure(go.Bar(x=np.arange(1, len(var_ratio)+1), y=var_ratio))
    fig.update_layout(
        title="Variance Explained by PCA Components",
        xaxis_title="Component #",
        yaxis_title="Explained Variance Ratio",
        template="plotly_white"
    )
    return fig

def plot_sensitive_bias(embeddings, sensitive_attr, labels=None):
    """Compare embedding distributions between sensitive groups."""
    reduced = reduce_embeddings(embeddings, method="pca", n_components=2)
    df = pd.DataFrame(reduced, columns=["x","y"])
    df["group"] = sensitive_attr
    if labels is not None:
        df["label"] = labels
    fig = px.scatter(
        df, x="x", y="y", color="group",
        title="Embedding Bias Across Sensitive Groups",
        hover_data=["label"] if labels is not None else None,
        opacity=0.8
    )
    fig.update_layout(template="plotly_white")
    return fig

def plot_class_balance_radar(labels):
    """Radar chart of class counts."""
    counts = pd.Series(labels).value_counts()
    categories = list(counts.index)
    values = counts.values.tolist()
    values += values[:1]  # close the loop
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(r=values, theta=categories + [categories[0]],
                                  fill='toself', name='Class Count'))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True)), showlegend=False,
                      title="Class Balance Radar Plot")
    return fig

def plot_embedding_correlation(embeddings, sensitive_attr):
    """Correlation heatmap between embedding dims and sensitive attributes."""
    emb_df = pd.DataFrame(embeddings)
    emb_df["sensitive"] = sensitive_attr
    corr = emb_df.corr()
    fig = go.Figure(data=go.Heatmap(z=corr.values, x=corr.columns, y=corr.columns, colorscale="RdBu"))
    fig.update_layout(title="Embedding–Sensitive Attribute Correlation Heatmap")
    return fig

if __name__ == "__main__":
    data = load_embedding_data(".")

    emb = data["embeddings"]
    labels = data["labels"]
    ids = data["ids"]

    reduced = reduce_embeddings(emb, method="umap")

    # Basic scatter
    fig1 = plot_embedding_scatter(reduced, labels=labels, ids=ids, title="UMAP Projection (Colored by Labels)")
    fig1.show()

    # kNN-based cluster visualization (if graph available)
    if data["knn_indices"] is not None:
        fig2 = visualize_knn_graph(reduced, data["knn_indices"], labels=labels)
        fig2.show()

    # Similarity heatmap
    fig3 = plot_similarity_heatmap(emb, labels)
    fig3.show()
